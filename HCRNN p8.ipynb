{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:12.260441Z",
     "iopub.status.busy": "2023-03-21T03:12:12.259984Z",
     "iopub.status.idle": "2023-03-21T03:12:24.214036Z",
     "shell.execute_reply": "2023-03-21T03:12:24.211941Z",
     "shell.execute_reply.started": "2023-03-21T03:12:12.260404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in /opt/conda/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.218541Z",
     "iopub.status.busy": "2023-03-21T03:12:24.217945Z",
     "iopub.status.idle": "2023-03-21T03:12:24.228329Z",
     "shell.execute_reply": "2023-03-21T03:12:24.226706Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.218480Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.230559Z",
     "iopub.status.busy": "2023-03-21T03:12:24.230153Z",
     "iopub.status.idle": "2023-03-21T03:12:24.251602Z",
     "shell.execute_reply": "2023-03-21T03:12:24.249609Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.230518Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.253525Z",
     "iopub.status.busy": "2023-03-21T03:12:24.253074Z",
     "iopub.status.idle": "2023-03-21T03:12:24.341642Z",
     "shell.execute_reply": "2023-03-21T03:12:24.340528Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.253453Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/answerscript4/p8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.345741Z",
     "iopub.status.busy": "2023-03-21T03:12:24.345208Z",
     "iopub.status.idle": "2023-03-21T03:12:24.355320Z",
     "shell.execute_reply": "2023-03-21T03:12:24.354079Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.345691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.357028Z",
     "iopub.status.busy": "2023-03-21T03:12:24.356652Z",
     "iopub.status.idle": "2023-03-21T03:12:24.373266Z",
     "shell.execute_reply": "2023-03-21T03:12:24.371648Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.356969Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ind = df.loc[df['essay_set']==8]\n",
    "\n",
    "df_ind = df_ind[['essay','domain1_score']]\n",
    "\n",
    "df_ind = df_ind.sort_values(by= [\"domain1_score\"], ascending=False)\n",
    "answer_sheet = df_ind.iloc[0]['essay']\n",
    "df_ind = df_ind.drop(0)\n",
    "students_answers = list(df['essay'].values)\n",
    "marks_org = list(df['domain1_score'].values)\n",
    "t=max(marks_org)\n",
    "#df.apply(preprocess_text1,pandas column name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.376524Z",
     "iopub.status.busy": "2023-03-21T03:12:24.375229Z",
     "iopub.status.idle": "2023-03-21T03:12:24.409817Z",
     "shell.execute_reply": "2023-03-21T03:12:24.408415Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.376467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12255</td>\n",
       "      <td>20716</td>\n",
       "      <td>8</td>\n",
       "      <td>A long time ago when I was in third grade I h...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12256</td>\n",
       "      <td>20717</td>\n",
       "      <td>8</td>\n",
       "      <td>Softball has to be one of the single most gre...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12257</td>\n",
       "      <td>20718</td>\n",
       "      <td>8</td>\n",
       "      <td>Some people like making people laugh, I love ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12258</td>\n",
       "      <td>20719</td>\n",
       "      <td>8</td>\n",
       "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12259</td>\n",
       "      <td>20721</td>\n",
       "      <td>8</td>\n",
       "      <td>Well ima tell a story about the time i got @CA...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0       12255     20716          8   \n",
       "1       12256     20717          8   \n",
       "2       12257     20718          8   \n",
       "3       12258     20719          8   \n",
       "4       12259     20721          8   \n",
       "\n",
       "                                               essay  rater1_domain1  \\\n",
       "0   A long time ago when I was in third grade I h...            18.0   \n",
       "1   Softball has to be one of the single most gre...            21.0   \n",
       "2   Some people like making people laugh, I love ...            15.0   \n",
       "3   \"LAUGHTER\"  @CAPS1 I hang out with my friends...            12.0   \n",
       "4  Well ima tell a story about the time i got @CA...            11.0   \n",
       "\n",
       "   rater2_domain1  rater3_domain1  domain1_score  rater1_domain2  \\\n",
       "0            16.0             NaN           34.0             NaN   \n",
       "1            26.0            46.0           46.0             NaN   \n",
       "2            20.0            40.0           40.0             NaN   \n",
       "3            20.0            30.0           30.0             NaN   \n",
       "4            15.0             NaN           26.0             NaN   \n",
       "\n",
       "   rater2_domain2  ...  rater2_trait3  rater2_trait4  rater2_trait5  \\\n",
       "0             NaN  ...            4.0            4.0            3.0   \n",
       "1             NaN  ...            6.0            6.0            5.0   \n",
       "2             NaN  ...            5.0            4.0            4.0   \n",
       "3             NaN  ...            4.0            4.0            4.0   \n",
       "4             NaN  ...            3.0            3.0            3.0   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            3.0            NaN            NaN            NaN            NaN   \n",
       "1            5.0            5.0            5.0            5.0            5.0   \n",
       "2            4.0            4.0            4.0            4.0            4.0   \n",
       "3            4.0            3.0            3.0            3.0            3.0   \n",
       "4            3.0            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN  \n",
       "1            5.0            4.0  \n",
       "2            4.0            4.0  \n",
       "3            3.0            3.0  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:12:24.412286Z",
     "iopub.status.busy": "2023-03-21T03:12:24.411799Z",
     "iopub.status.idle": "2023-03-21T03:13:01.663937Z",
     "shell.execute_reply": "2023-03-21T03:13:01.662800Z",
     "shell.execute_reply.started": "2023-03-21T03:12:24.412232Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the maximum sequence length and embedding dimension\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Set the number of LSTM units and dropout rate\n",
    "NUM_LSTM_UNITS = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# Set the batch size and number of epochs\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define the function to preprocess the text\n",
    "def preprocess_text(x, remove_stopwords=False):\n",
    "    x = x.lower()\n",
    "    x = re.sub(\"[^a-z\\s+]\",\"\",x)\n",
    "    if remove_stopwords:\n",
    "        x = \" \".join([word for word in x.split() if word not in stopwords.words('english')])\n",
    "    return x\n",
    "\n",
    "# Load the essays dataset\n",
    "essays_df = pd.read_csv('/kaggle/input/answerscript4/p7.csv', encoding='latin-1')\n",
    "\n",
    "# Remove essays that have a domain1_score of NaN\n",
    "essays_df = essays_df[~essays_df['domain1_score'].isna()]\n",
    "\n",
    "# Remove stopwords from the essays\n",
    "essays_df['essay'] = essays_df['essay'].apply(preprocess_text, remove_stopwords=True)\n",
    "essays_df['expected']=answer_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:13:01.665614Z",
     "iopub.status.busy": "2023-03-21T03:13:01.665287Z",
     "iopub.status.idle": "2023-03-21T03:13:02.945776Z",
     "shell.execute_reply": "2023-03-21T03:13:02.944586Z",
     "shell.execute_reply.started": "2023-03-21T03:13:01.665582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(essays_df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['essay'])\n",
    "\n",
    "# Convert the texts to sequences and pad them to the specified maximum length\n",
    "X_expected_train = pad_sequences(tokenizer.texts_to_sequences(train_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_train = pad_sequences(tokenizer.texts_to_sequences(train_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_train = train_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_val = pad_sequences(tokenizer.texts_to_sequences(val_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_val = pad_sequences(tokenizer.texts_to_sequences(val_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_val = val_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_test = pad_sequences(tokenizer.texts_to_sequences(test_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_test = pad_sequences(tokenizer.texts_to_sequences(test_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_test = test_df['domain1_score'].values /t\n",
    "\n",
    "# Define the inputs and embedding layer\n",
    "expected_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='expected_input')\n",
    "actual_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='actual_input')\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Encode the inputs with the embedding layer\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:13:02.947582Z",
     "iopub.status.busy": "2023-03-21T03:13:02.947255Z",
     "iopub.status.idle": "2023-03-21T03:18:29.442879Z",
     "shell.execute_reply": "2023-03-21T03:18:29.441608Z",
     "shell.execute_reply.started": "2023-03-21T03:13:02.947550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 30s 2s/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 31s 2s/step - loss: 0.0457 - mae: 0.0457 - val_loss: 0.0457 - val_mae: 0.0457\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.0349 - mae: 0.0349 - val_loss: 0.0473 - val_mae: 0.0473\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.0485 - val_mae: 0.0485\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0475 - val_mae: 0.0475\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 31s 2s/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0487 - val_mae: 0.0487\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 30s 2s/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0469 - val_mae: 0.0469\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 30s 1s/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0466 - val_mae: 0.0466\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 30s 1s/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0484 - val_mae: 0.0484\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.0441 - mae: 0.0441\n",
      "Test Loss: 0.04411724582314491\n",
      "Test MAE: 0.04411724582314491\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(NUM_LSTM_UNITS)\n",
    "\n",
    "# Define the dropout layer\n",
    "dropout_layer = Dropout(DROPOUT_RATE)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Encode the expected and actual inputs\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n",
    "# Pass the expected and actual inputs through the LSTM layer\n",
    "expected_output = lstm_layer(expected_encoded)\n",
    "actual_output = lstm_layer(actual_encoded)\n",
    "\n",
    "# Apply dropout to the LSTM outputs\n",
    "expected_output = dropout_layer(expected_output)\n",
    "actual_output = dropout_layer(actual_output)\n",
    "\n",
    "# Pass the LSTM outputs through the output layer\n",
    "expected_output = output_layer(expected_output)\n",
    "actual_output = output_layer(actual_output)\n",
    "\n",
    "\n",
    "model_inputs = [expected_input, actual_input]\n",
    "model_outputs = [actual_output]\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "# Compile the model with MAE as the loss function\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=[X_expected_train, X_actual_train], y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([X_expected_val, X_actual_val], y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate([X_expected_test, X_actual_test], y_test, batch_size=BATCH_SIZE)\n",
    "print('Test Loss:', loss)\n",
    "print('Test MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
