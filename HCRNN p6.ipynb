{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:22.160211Z",
     "iopub.status.busy": "2023-03-21T03:02:22.159850Z",
     "iopub.status.idle": "2023-03-21T03:02:31.452487Z",
     "shell.execute_reply": "2023-03-21T03:02:31.450874Z",
     "shell.execute_reply.started": "2023-03-21T03:02:22.160178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in /opt/conda/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.21.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.455602Z",
     "iopub.status.busy": "2023-03-21T03:02:31.455213Z",
     "iopub.status.idle": "2023-03-21T03:02:31.465434Z",
     "shell.execute_reply": "2023-03-21T03:02:31.463731Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.455567Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.467602Z",
     "iopub.status.busy": "2023-03-21T03:02:31.467179Z",
     "iopub.status.idle": "2023-03-21T03:02:31.482259Z",
     "shell.execute_reply": "2023-03-21T03:02:31.480467Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.467562Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.486522Z",
     "iopub.status.busy": "2023-03-21T03:02:31.486064Z",
     "iopub.status.idle": "2023-03-21T03:02:31.549066Z",
     "shell.execute_reply": "2023-03-21T03:02:31.548274Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.486476Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/answerscript4/p6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.551572Z",
     "iopub.status.busy": "2023-03-21T03:02:31.550575Z",
     "iopub.status.idle": "2023-03-21T03:02:31.559682Z",
     "shell.execute_reply": "2023-03-21T03:02:31.558426Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.551515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.561453Z",
     "iopub.status.busy": "2023-03-21T03:02:31.561117Z",
     "iopub.status.idle": "2023-03-21T03:02:31.578082Z",
     "shell.execute_reply": "2023-03-21T03:02:31.576288Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.561424Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ind = df.loc[df['essay_set']==6]\n",
    "\n",
    "df_ind = df_ind[['essay','domain1_score']]\n",
    "\n",
    "df_ind = df_ind.sort_values(by= [\"domain1_score\"], ascending=False)\n",
    "answer_sheet = df_ind.iloc[0]['essay']\n",
    "df_ind = df_ind.drop(0)\n",
    "students_answers = list(df['essay'].values)\n",
    "marks_org = list(df['domain1_score'].values)\n",
    "t=max(marks_org)\n",
    "#df.apply(preprocess_text1,pandas column name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.579775Z",
     "iopub.status.busy": "2023-03-21T03:02:31.579465Z",
     "iopub.status.idle": "2023-03-21T03:02:31.606912Z",
     "shell.execute_reply": "2023-03-21T03:02:31.604928Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.579746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8886</td>\n",
       "      <td>14834</td>\n",
       "      <td>6</td>\n",
       "      <td>There were many obstacles that the builders fa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8887</td>\n",
       "      <td>14835</td>\n",
       "      <td>6</td>\n",
       "      <td>Him from the start, there would have been many...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8888</td>\n",
       "      <td>14836</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8889</td>\n",
       "      <td>14837</td>\n",
       "      <td>6</td>\n",
       "      <td>In the passage The Mooring Mast by Marcia Amid...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8890</td>\n",
       "      <td>14838</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State Building face...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0        8886     14834          6   \n",
       "1        8887     14835          6   \n",
       "2        8888     14836          6   \n",
       "3        8889     14837          6   \n",
       "4        8890     14838          6   \n",
       "\n",
       "                                               essay  rater1_domain1  \\\n",
       "0  There were many obstacles that the builders fa...             2.0   \n",
       "1  Him from the start, there would have been many...             3.0   \n",
       "2  The builders of the Empire State Building face...             3.0   \n",
       "3  In the passage The Mooring Mast by Marcia Amid...             1.0   \n",
       "4  The builders of the Empire State Building face...             3.0   \n",
       "\n",
       "   rater2_domain1  rater3_domain1  domain1_score  rater1_domain2  \\\n",
       "0             2.0             NaN            2.0             NaN   \n",
       "1             3.0             NaN            3.0             NaN   \n",
       "2             4.0             NaN            4.0             NaN   \n",
       "3             1.0             NaN            1.0             NaN   \n",
       "4             3.0             NaN            3.0             NaN   \n",
       "\n",
       "   rater2_domain2  ...  rater2_trait3  rater2_trait4  rater2_trait5  \\\n",
       "0             NaN  ...            NaN            NaN            NaN   \n",
       "1             NaN  ...            NaN            NaN            NaN   \n",
       "2             NaN  ...            NaN            NaN            NaN   \n",
       "3             NaN  ...            NaN            NaN            NaN   \n",
       "4             NaN  ...            NaN            NaN            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:02:31.609058Z",
     "iopub.status.busy": "2023-03-21T03:02:31.608725Z",
     "iopub.status.idle": "2023-03-21T03:03:00.640533Z",
     "shell.execute_reply": "2023-03-21T03:03:00.639544Z",
     "shell.execute_reply.started": "2023-03-21T03:02:31.609029Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the maximum sequence length and embedding dimension\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Set the number of LSTM units and dropout rate\n",
    "NUM_LSTM_UNITS = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# Set the batch size and number of epochs\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define the function to preprocess the text\n",
    "def preprocess_text(x, remove_stopwords=False):\n",
    "    x = x.lower()\n",
    "    x = re.sub(\"[^a-z\\s+]\",\"\",x)\n",
    "    if remove_stopwords:\n",
    "        x = \" \".join([word for word in x.split() if word not in stopwords.words('english')])\n",
    "    return x\n",
    "\n",
    "# Load the essays dataset\n",
    "essays_df = pd.read_csv('/kaggle/input/answerscript4/p7.csv', encoding='latin-1')\n",
    "\n",
    "# Remove essays that have a domain1_score of NaN\n",
    "essays_df = essays_df[~essays_df['domain1_score'].isna()]\n",
    "\n",
    "# Remove stopwords from the essays\n",
    "essays_df['essay'] = essays_df['essay'].apply(preprocess_text, remove_stopwords=True)\n",
    "essays_df['expected']=answer_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:03:00.641931Z",
     "iopub.status.busy": "2023-03-21T03:03:00.641643Z",
     "iopub.status.idle": "2023-03-21T03:03:00.984358Z",
     "shell.execute_reply": "2023-03-21T03:03:00.983582Z",
     "shell.execute_reply.started": "2023-03-21T03:03:00.641904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(essays_df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['essay'])\n",
    "\n",
    "# Convert the texts to sequences and pad them to the specified maximum length\n",
    "X_expected_train = pad_sequences(tokenizer.texts_to_sequences(train_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_train = pad_sequences(tokenizer.texts_to_sequences(train_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_train = train_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_val = pad_sequences(tokenizer.texts_to_sequences(val_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_val = pad_sequences(tokenizer.texts_to_sequences(val_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_val = val_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_test = pad_sequences(tokenizer.texts_to_sequences(test_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_test = pad_sequences(tokenizer.texts_to_sequences(test_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_test = test_df['domain1_score'].values /t\n",
    "\n",
    "# Define the inputs and embedding layer\n",
    "expected_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='expected_input')\n",
    "actual_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='actual_input')\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Encode the inputs with the embedding layer\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T03:03:00.986954Z",
     "iopub.status.busy": "2023-03-21T03:03:00.986657Z",
     "iopub.status.idle": "2023-03-21T03:07:26.335947Z",
     "shell.execute_reply": "2023-03-21T03:07:26.335090Z",
     "shell.execute_reply.started": "2023-03-21T03:03:00.986928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 26s 1s/step - loss: 3.2380 - mae: 3.2380 - val_loss: 2.9526 - val_mae: 2.9526\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 22s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 25s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 25s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 22s 1s/step - loss: 3.0317 - mae: 3.0317 - val_loss: 2.9525 - val_mae: 2.9525\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 2.9522 - mae: 2.9522\n",
      "Test Loss: 2.952237367630005\n",
      "Test MAE: 2.952237367630005\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(NUM_LSTM_UNITS)\n",
    "\n",
    "# Define the dropout layer\n",
    "dropout_layer = Dropout(DROPOUT_RATE)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Encode the expected and actual inputs\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n",
    "# Pass the expected and actual inputs through the LSTM layer\n",
    "expected_output = lstm_layer(expected_encoded)\n",
    "actual_output = lstm_layer(actual_encoded)\n",
    "\n",
    "# Apply dropout to the LSTM outputs\n",
    "expected_output = dropout_layer(expected_output)\n",
    "actual_output = dropout_layer(actual_output)\n",
    "\n",
    "# Pass the LSTM outputs through the output layer\n",
    "expected_output = output_layer(expected_output)\n",
    "actual_output = output_layer(actual_output)\n",
    "\n",
    "\n",
    "model_inputs = [expected_input, actual_input]\n",
    "model_outputs = [actual_output]\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "# Compile the model with MAE as the loss function\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=[X_expected_train, X_actual_train], y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([X_expected_val, X_actual_val], y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate([X_expected_test, X_actual_test], y_test, batch_size=BATCH_SIZE)\n",
    "print('Test Loss:', loss)\n",
    "print('Test MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
