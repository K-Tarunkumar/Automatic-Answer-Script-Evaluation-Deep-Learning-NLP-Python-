{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:01.264691Z",
     "iopub.status.busy": "2023-03-21T02:56:01.264194Z",
     "iopub.status.idle": "2023-03-21T02:56:10.628570Z",
     "shell.execute_reply": "2023-03-21T02:56:10.627731Z",
     "shell.execute_reply.started": "2023-03-21T02:56:01.264646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in /opt/conda/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.21.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.630776Z",
     "iopub.status.busy": "2023-03-21T02:56:10.630436Z",
     "iopub.status.idle": "2023-03-21T02:56:10.640741Z",
     "shell.execute_reply": "2023-03-21T02:56:10.638979Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.630747Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.642426Z",
     "iopub.status.busy": "2023-03-21T02:56:10.642112Z",
     "iopub.status.idle": "2023-03-21T02:56:10.652720Z",
     "shell.execute_reply": "2023-03-21T02:56:10.650993Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.642399Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.656381Z",
     "iopub.status.busy": "2023-03-21T02:56:10.655983Z",
     "iopub.status.idle": "2023-03-21T02:56:10.706565Z",
     "shell.execute_reply": "2023-03-21T02:56:10.704925Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.656348Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/answerscript4/p2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.708698Z",
     "iopub.status.busy": "2023-03-21T02:56:10.708320Z",
     "iopub.status.idle": "2023-03-21T02:56:10.717474Z",
     "shell.execute_reply": "2023-03-21T02:56:10.715971Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.708668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.720653Z",
     "iopub.status.busy": "2023-03-21T02:56:10.719890Z",
     "iopub.status.idle": "2023-03-21T02:56:10.734724Z",
     "shell.execute_reply": "2023-03-21T02:56:10.733781Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.720600Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ind = df.loc[df['essay_set']==2]\n",
    "\n",
    "df_ind = df_ind[['essay','domain1_score']]\n",
    "\n",
    "df_ind = df_ind.sort_values(by= [\"domain1_score\"], ascending=False)\n",
    "answer_sheet = df_ind.iloc[0]['essay']\n",
    "df_ind = df_ind.drop(0)\n",
    "students_answers = list(df['essay'].values)\n",
    "marks_org = list(df['domain1_score'].values)\n",
    "t=max(marks_org)\n",
    "#df.apply(preprocess_text1,pandas column name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.736884Z",
     "iopub.status.busy": "2023-03-21T02:56:10.736322Z",
     "iopub.status.idle": "2023-03-21T02:56:10.779428Z",
     "shell.execute_reply": "2023-03-21T02:56:10.777345Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.736855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1783</td>\n",
       "      <td>2978</td>\n",
       "      <td>2</td>\n",
       "      <td>Certain materials being removed from libraries...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1784</td>\n",
       "      <td>2979</td>\n",
       "      <td>2</td>\n",
       "      <td>Write a persuasive essay to a newspaper reflec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1785</td>\n",
       "      <td>2980</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think that libraries should remove cert...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1786</td>\n",
       "      <td>2981</td>\n",
       "      <td>2</td>\n",
       "      <td>In @DATE1's world, there are many things found...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1787</td>\n",
       "      <td>2982</td>\n",
       "      <td>2</td>\n",
       "      <td>In life you have the 'offensive things'. The l...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0        1783      2978          2   \n",
       "1        1784      2979          2   \n",
       "2        1785      2980          2   \n",
       "3        1786      2981          2   \n",
       "4        1787      2982          2   \n",
       "\n",
       "                                               essay  rater1_domain1  \\\n",
       "0  Certain materials being removed from libraries...             4.0   \n",
       "1  Write a persuasive essay to a newspaper reflec...             1.0   \n",
       "2  Do you think that libraries should remove cert...             2.0   \n",
       "3  In @DATE1's world, there are many things found...             4.0   \n",
       "4  In life you have the 'offensive things'. The l...             4.0   \n",
       "\n",
       "   rater2_domain1  rater3_domain1  domain1_score  rater1_domain2  \\\n",
       "0             4.0             NaN            4.0             4.0   \n",
       "1             2.0             NaN            1.0             1.0   \n",
       "2             3.0             NaN            2.0             3.0   \n",
       "3             4.0             NaN            4.0             4.0   \n",
       "4             4.0             NaN            4.0             4.0   \n",
       "\n",
       "   rater2_domain2  ...  rater2_trait3  rater2_trait4  rater2_trait5  \\\n",
       "0             4.0  ...            NaN            NaN            NaN   \n",
       "1             2.0  ...            NaN            NaN            NaN   \n",
       "2             3.0  ...            NaN            NaN            NaN   \n",
       "3             4.0  ...            NaN            NaN            NaN   \n",
       "4             4.0  ...            NaN            NaN            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:10.781150Z",
     "iopub.status.busy": "2023-03-21T02:56:10.780743Z",
     "iopub.status.idle": "2023-03-21T02:56:39.533576Z",
     "shell.execute_reply": "2023-03-21T02:56:39.532557Z",
     "shell.execute_reply.started": "2023-03-21T02:56:10.781113Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the maximum sequence length and embedding dimension\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Set the number of LSTM units and dropout rate\n",
    "NUM_LSTM_UNITS = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# Set the batch size and number of epochs\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define the function to preprocess the text\n",
    "def preprocess_text(x, remove_stopwords=False):\n",
    "    x = x.lower()\n",
    "    x = re.sub(\"[^a-z\\s+]\",\"\",x)\n",
    "    if remove_stopwords:\n",
    "        x = \" \".join([word for word in x.split() if word not in stopwords.words('english')])\n",
    "    return x\n",
    "\n",
    "# Load the essays dataset\n",
    "essays_df = pd.read_csv('/kaggle/input/answerscript4/p7.csv', encoding='latin-1')\n",
    "\n",
    "# Remove essays that have a domain1_score of NaN\n",
    "essays_df = essays_df[~essays_df['domain1_score'].isna()]\n",
    "\n",
    "# Remove stopwords from the essays\n",
    "essays_df['essay'] = essays_df['essay'].apply(preprocess_text, remove_stopwords=True)\n",
    "essays_df['expected']=answer_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:39.535144Z",
     "iopub.status.busy": "2023-03-21T02:56:39.534789Z",
     "iopub.status.idle": "2023-03-21T02:56:40.338843Z",
     "shell.execute_reply": "2023-03-21T02:56:40.337362Z",
     "shell.execute_reply.started": "2023-03-21T02:56:39.535107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(essays_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['essay'])\n",
    "\n",
    "# Convert the texts to sequences and pad them to the specified maximum length\n",
    "X_expected_train = pad_sequences(tokenizer.texts_to_sequences(train_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_train = pad_sequences(tokenizer.texts_to_sequences(train_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_train = train_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_val = pad_sequences(tokenizer.texts_to_sequences(val_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_val = pad_sequences(tokenizer.texts_to_sequences(val_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_val = val_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_test = pad_sequences(tokenizer.texts_to_sequences(test_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_test = pad_sequences(tokenizer.texts_to_sequences(test_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_test = test_df['domain1_score'].values /t\n",
    "\n",
    "# Define the inputs and embedding layer\n",
    "expected_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='expected_input')\n",
    "actual_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='actual_input')\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Encode the inputs with the embedding layer\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T02:56:40.342122Z",
     "iopub.status.busy": "2023-03-21T02:56:40.341861Z",
     "iopub.status.idle": "2023-03-21T03:01:06.107955Z",
     "shell.execute_reply": "2023-03-21T03:01:06.107187Z",
     "shell.execute_reply.started": "2023-03-21T02:56:40.342096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 25s 1s/step - loss: 1.8947 - mae: 1.8947 - val_loss: 1.6351 - val_mae: 1.6351\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 25s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 24s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 23s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 25s 1s/step - loss: 1.6920 - mae: 1.6920 - val_loss: 1.6350 - val_mae: 1.6350\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 1.6348 - mae: 1.6348\n",
      "Test Loss: 1.6348278522491455\n",
      "Test MAE: 1.6348278522491455\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(NUM_LSTM_UNITS)\n",
    "\n",
    "# Define the dropout layer\n",
    "dropout_layer = Dropout(DROPOUT_RATE)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Encode the expected and actual inputs\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n",
    "# Pass the expected and actual inputs through the LSTM layer\n",
    "expected_output = lstm_layer(expected_encoded)\n",
    "actual_output = lstm_layer(actual_encoded)\n",
    "\n",
    "# Apply dropout to the LSTM outputs\n",
    "expected_output = dropout_layer(expected_output)\n",
    "actual_output = dropout_layer(actual_output)\n",
    "\n",
    "# Pass the LSTM outputs through the output layer\n",
    "expected_output = output_layer(expected_output)\n",
    "actual_output = output_layer(actual_output)\n",
    "\n",
    "\n",
    "model_inputs = [expected_input, actual_input]\n",
    "model_outputs = [actual_output]\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "# Compile the model with MAE as the loss function\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=[X_expected_train, X_actual_train], y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([X_expected_val, X_actual_val], y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate([X_expected_test, X_actual_test], y_test, batch_size=BATCH_SIZE)\n",
    "print('Test Loss:', loss)\n",
    "print('Test MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
