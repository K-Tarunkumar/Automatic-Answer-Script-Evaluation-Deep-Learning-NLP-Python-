{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:31:35.434668Z",
     "iopub.status.busy": "2023-03-14T21:31:35.434215Z",
     "iopub.status.idle": "2023-03-14T21:31:49.416729Z",
     "shell.execute_reply": "2023-03-14T21:31:49.415602Z",
     "shell.execute_reply.started": "2023-03-14T21:31:35.434626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras-Preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.21.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Installing collected packages: Keras-Preprocessing\n",
      "Successfully installed Keras-Preprocessing-1.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:31:49.421727Z",
     "iopub.status.busy": "2023-03-14T21:31:49.419819Z",
     "iopub.status.idle": "2023-03-14T21:31:59.377882Z",
     "shell.execute_reply": "2023-03-14T21:31:59.376662Z",
     "shell.execute_reply.started": "2023-03-14T21:31:49.421672Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Concatenate, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:31:59.381516Z",
     "iopub.status.busy": "2023-03-14T21:31:59.379563Z",
     "iopub.status.idle": "2023-03-14T21:31:59.388103Z",
     "shell.execute_reply": "2023-03-14T21:31:59.386833Z",
     "shell.execute_reply.started": "2023-03-14T21:31:59.381459Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:37:33.586750Z",
     "iopub.status.busy": "2023-03-14T21:37:33.585301Z",
     "iopub.status.idle": "2023-03-14T21:37:33.644864Z",
     "shell.execute_reply": "2023-03-14T21:37:33.643585Z",
     "shell.execute_reply.started": "2023-03-14T21:37:33.586698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/answerscript4/p3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:37:33.647961Z",
     "iopub.status.busy": "2023-03-14T21:37:33.647232Z",
     "iopub.status.idle": "2023-03-14T21:37:33.733092Z",
     "shell.execute_reply": "2023-03-14T21:37:33.732079Z",
     "shell.execute_reply.started": "2023-03-14T21:37:33.647919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:37:33.735364Z",
     "iopub.status.busy": "2023-03-14T21:37:33.734672Z",
     "iopub.status.idle": "2023-03-14T21:37:33.759082Z",
     "shell.execute_reply": "2023-03-14T21:37:33.757554Z",
     "shell.execute_reply.started": "2023-03-14T21:37:33.735321Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ind = df.loc[df['essay_set']==3]\n",
    "\n",
    "df_ind = df_ind[['essay','domain1_score']]\n",
    "\n",
    "df_ind = df_ind.sort_values(by= [\"domain1_score\"], ascending=False)\n",
    "answer_sheet = df_ind.iloc[0]['essay']\n",
    "df_ind = df_ind.drop(0)\n",
    "students_answers = list(df['essay'].values)\n",
    "marks_org = list(df['domain1_score'].values)\n",
    "t=max(marks_org)\n",
    "#df.apply(preprocess_text1,pandas column name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:37:33.761308Z",
     "iopub.status.busy": "2023-03-14T21:37:33.760646Z",
     "iopub.status.idle": "2023-03-14T21:37:33.802421Z",
     "shell.execute_reply": "2023-03-14T21:37:33.800855Z",
     "shell.execute_reply.started": "2023-03-14T21:37:33.761262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3583</td>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3584</td>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3585</td>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3586</td>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3587</td>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0        3583      5978          3   \n",
       "1        3584      5979          3   \n",
       "2        3585      5980          3   \n",
       "3        3586      5981          3   \n",
       "4        3587      5982          3   \n",
       "\n",
       "                                               essay  rater1_domain1  \\\n",
       "0  The features of the setting affect the cyclist...             1.0   \n",
       "1  The features of the setting affected the cycli...             2.0   \n",
       "2  Everyone travels to unfamiliar places. Sometim...             1.0   \n",
       "3  I believe the features of the cyclist affected...             1.0   \n",
       "4  The setting effects the cyclist because of the...             2.0   \n",
       "\n",
       "   rater2_domain1  rater3_domain1  domain1_score  rater1_domain2  \\\n",
       "0             1.0             NaN            1.0             NaN   \n",
       "1             2.0             NaN            2.0             NaN   \n",
       "2             1.0             NaN            1.0             NaN   \n",
       "3             1.0             NaN            1.0             NaN   \n",
       "4             2.0             NaN            2.0             NaN   \n",
       "\n",
       "   rater2_domain2  ...  rater2_trait3  rater2_trait4  rater2_trait5  \\\n",
       "0             NaN  ...            NaN            NaN            NaN   \n",
       "1             NaN  ...            NaN            NaN            NaN   \n",
       "2             NaN  ...            NaN            NaN            NaN   \n",
       "3             NaN  ...            NaN            NaN            NaN   \n",
       "4             NaN  ...            NaN            NaN            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:37:33.806553Z",
     "iopub.status.busy": "2023-03-14T21:37:33.805946Z",
     "iopub.status.idle": "2023-03-14T21:38:11.902243Z",
     "shell.execute_reply": "2023-03-14T21:38:11.901194Z",
     "shell.execute_reply.started": "2023-03-14T21:37:33.806498Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the maximum sequence length and embedding dimension\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Set the number of LSTM units and dropout rate\n",
    "NUM_LSTM_UNITS = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# Set the batch size and number of epochs\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define the function to preprocess the text\n",
    "def preprocess_text(x, remove_stopwords=False):\n",
    "    x = x.lower()\n",
    "    x = re.sub(\"[^a-z\\s+]\",\"\",x)\n",
    "    if remove_stopwords:\n",
    "        x = \" \".join([word for word in x.split() if word not in stopwords.words('english')])\n",
    "    return x\n",
    "\n",
    "# Load the essays dataset\n",
    "essays_df = pd.read_csv('/kaggle/input/answerscript4/p7.csv', encoding='latin-1')\n",
    "\n",
    "# Remove essays that have a domain1_score of NaN\n",
    "essays_df = essays_df[~essays_df['domain1_score'].isna()]\n",
    "\n",
    "# Remove stopwords from the essays\n",
    "essays_df['essay'] = essays_df['essay'].apply(preprocess_text, remove_stopwords=True)\n",
    "essays_df['expected']=answer_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:38:11.904736Z",
     "iopub.status.busy": "2023-03-14T21:38:11.904041Z",
     "iopub.status.idle": "2023-03-14T21:38:12.481752Z",
     "shell.execute_reply": "2023-03-14T21:38:12.480382Z",
     "shell.execute_reply.started": "2023-03-14T21:38:11.904697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(essays_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['essay'])\n",
    "\n",
    "# Convert the texts to sequences and pad them to the specified maximum length\n",
    "X_expected_train = pad_sequences(tokenizer.texts_to_sequences(train_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_train = pad_sequences(tokenizer.texts_to_sequences(train_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_train = train_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_val = pad_sequences(tokenizer.texts_to_sequences(val_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_val = pad_sequences(tokenizer.texts_to_sequences(val_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_val = val_df['domain1_score'].values /t\n",
    "\n",
    "X_expected_test = pad_sequences(tokenizer.texts_to_sequences(test_df['expected']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_actual_test = pad_sequences(tokenizer.texts_to_sequences(test_df['essay']), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_test = test_df['domain1_score'].values /t\n",
    "\n",
    "# Define the inputs and embedding layer\n",
    "expected_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='expected_input')\n",
    "actual_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='actual_input')\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Encode the inputs with the embedding layer\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T21:38:12.483840Z",
     "iopub.status.busy": "2023-03-14T21:38:12.483391Z",
     "iopub.status.idle": "2023-03-14T21:43:40.364661Z",
     "shell.execute_reply": "2023-03-14T21:43:40.363603Z",
     "shell.execute_reply.started": "2023-03-14T21:38:12.483793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 31s 1s/step - loss: 4.5843 - mae: 4.5843 - val_loss: 4.2701 - val_mae: 4.2701\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 4.3746 - mae: 4.3746 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 4.2696 - mae: 4.2696\n",
      "Test Loss: 4.26964807510376\n",
      "Test MAE: 4.26964807510376\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(NUM_LSTM_UNITS)\n",
    "\n",
    "# Define the dropout layer\n",
    "dropout_layer = Dropout(DROPOUT_RATE)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Encode the expected and actual inputs\n",
    "expected_encoded = embedding_layer(expected_input)\n",
    "actual_encoded = embedding_layer(actual_input)\n",
    "\n",
    "# Pass the expected and actual inputs through the LSTM layer\n",
    "expected_output = lstm_layer(expected_encoded)\n",
    "actual_output = lstm_layer(actual_encoded)\n",
    "\n",
    "# Apply dropout to the LSTM outputs\n",
    "expected_output = dropout_layer(expected_output)\n",
    "actual_output = dropout_layer(actual_output)\n",
    "\n",
    "# Pass the LSTM outputs through the output layer\n",
    "expected_output = output_layer(expected_output)\n",
    "actual_output = output_layer(actual_output)\n",
    "\n",
    "\n",
    "model_inputs = [expected_input, actual_input]\n",
    "model_outputs = [actual_output]\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "# Compile the model with MAE as the loss function\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=[X_expected_train, X_actual_train], y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([X_expected_val, X_actual_val], y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate([X_expected_test, X_actual_test], y_test, batch_size=BATCH_SIZE)\n",
    "print('Test Loss:', loss)\n",
    "print('Test MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
